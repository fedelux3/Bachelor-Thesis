\chapter{Analisi dei risultati}
\label{Analisi}

La performance del software \`e stata valutata tramite diversi test in cui vengono utilizzati database con diverso numero di record e diverse combinazioni di parametri.
\\\\
Il database di partenza utilizzato \`e quello relativo al Boston Crime Department del 2018 descritto nel capitolo precedente con $15\,648$ record. Tuttavia, non \`e stato utilizzato per\`o direttamente in quanto il numero di record \`e molto elevato. Con un alto numero di record, il tempo di elaborazione aumenta eccessivamente, pertanto si \`e preferito testare il software in suoi sottoinsiemi.\\
Per la generazione dei dataset sottoinsiemi viene copiato un record ogni $N$, in questo modo si mantengono le proporzioni delle frequenze tra i diversi tipi di eventi.\\
Sono stati generati 4 dataset sottoinsieme, i quali hanno i seguenti numeri di record:
\begin{enumerate}
	\item 1043 - 1 ogni 15 record
	\item 2235 - 1 ogni 7 record
	\item 3129 - 1 ogni 5 record
	\item 5216 - 1 ogni 3 record
\end{enumerate}
\noindent
I parametri utilizzati sono stati: $\theta$, numero di sequenze top ($Num$), $R$, $T$.

\paragraph{Il threshold $\theta$} \`e stato fissato a $0.25$, in quanto \`e il valore consigliato dal paper. Essendo un valore basso, l'algoritmo esclude a priori le sequenze poco significative e man mano incrementa il threshold per adattarlo al numero delle sequenze considerate nell'insieme $Top$, nel caso in cui esso superi il massimo numero di elementi consentito ($Num$).

\paragraph{Il numero di sequenze top $Num$} da considerare nel insieme $Top$ di output \`e stato fissato a 50, ovvero come output si considerano solo le prime cinquanta sequenze di tipi per \textit{participation index}. Il valore \`e frutto del compromesso tra numero di sequenze significative da visualizzare e tempi di computazione. Se si scegliesse un valore minore non si avrebbero sequenze di tipi significativi probabilmente utili. Se si segliesse un valore maggiore i tempi di computazione lieviterebbero esponenzialmente; inoltre, le sequenze ricavate oltre la cinquantesima posizione avranno, con alta probabilit\`a, un $PI$ basso, quindi poco rilevanti.
\\\\
I parametri di \textbf{raggio spaziale $R$} e \textbf{intervallo temporale $T$} sono variabili che vengono fissate in base al test da effettuare.\\
I valori scelti di questi due parametri variano entro i seguenti range:
\begin{itemize}
	\item $R$ varia da 1 a 3 km
	\item $T$ varia da 72 a 168 ore (da 3 giorni a 7 giorni)
\end{itemize} 
\clearpage

\section{Tempi di computazione}
La prima parte dell'analisi fatta riguarda i tempi di computazione e in particolare lo studio di come scala all'aumentare dei record il tempo di elaborazione. Sono state scelte 12 combinazioni dei parametri $R$ e $T$, applicate a tutti i quattro dataset. In concreto vi sono $12 \times 4 = 48$ test, 12 combinazioni per 4 dataset.\\
In Tabella 5.1 vengono mostrati i test effettuati con i tempi di computazione, suddivisi in base a: raggio spaziale, intervallo temporale e numero di record.

\begin{table}[h]
	\centering
	\begin{tabular}{c|c|c|c|c|c|c}
		\hline
		\multirow{2}{1cm}{\textbf{comb}} & \multirow{2}{2.2cm}{\textbf{raggio spaziale}} & \multirow{2}{2.2cm}{\textbf{intervallo temporale}} & \multicolumn{4}{c}{\textbf{tempo per numero di record}} \\
		& & & \textbf{1043} & \textbf{2235} & \textbf{3129} & \textbf{5216} \\
		\hline
		1 & 2 & 168 & 10 & 87 & 198 & 693 \\
		2 & 1.5 & 168 & 7 & 50 & 158 & 538 \\
		3 & 1.5 & 120 & 7 & 42 & 116 & 475 \\
		4 & 3 & 120	& 13 & 105 & 247 & 815 \\
		5 & 1 & 120 & 7 & 30 & 71 & 234 \\
		6 & 1 & 72 & 7 & 30 & 60 & 182 \\
		7 & 2 & 120 & 8 & 68 & 181 & 624 \\
		8 & 3 & 72 & 9 & 81 & 204 & 668 \\
		9 & 1.5 & 72 & 7 & 33 & 74 & 307 \\
		10 & 3 & 168 & 20 & 117 & 267 & 818 \\
		11 & 2 & 72 & 7 & 43 & 115 & 492 \\
		12 & 1 & 168 & 7 & 32 & 85 & 362 \\
		\hline
	\end{tabular}
	\caption{tempi in secondi dei test effettuati}
\end{table}
\noindent
Per comprendere come il software scali per numero di record vengono fissati i parametri di raggio spaziale $R$ e intervallo temporale $T$, in questo modo \`e possibile valutare l'andamento del tempo di computazione legato alla sola variazione di numero di record. Seguendo la procedura per tutte le combinazioni di raggio e tempo utilizzate ne risulta il grafico in Figura 5.1.\\
Una linea del grafico rappresenta una serie di test effettuati sui tutti i quattro dataset fissando una coppia di parametri $R$ e $T$. Le serie di test vengono effettuate per tutte le 12 combinazioni e i risultati rappresentati in figura.\\
\\
Come era prevedibile, i test che impiegano pi\`u tempo ad essere elaborati sono quelli con \textit{neighborhood} pi\`u ampio, sia per quanto riguarda il raggio spaziale sia quello temporale.\\
Un aspetto rilevante \`e l'andamento \textbf{non lineare} del tempo all'aumentare del numero di record. Al contrario, con un numero sufficientemente alto di record, si pu\`o pensare che il software tenda ad un tempo esponenziale. Lo si evince soprattutto quando il numero di record sale da $3129$ a $5216$.\\
Da notare inoltre che, per un \textit{vicinato} pi\`u ristretto, l'incremento dei tempi legato al numero di record \`e meno marcato, ad esempio per $R = 1 $, $ T = 72$.

\begin{figure}[h]
	\hspace{-3cm}
	\includegraphics[height=0.75 \linewidth]{tempi12.png}
	\caption{tempi di computazione in relazione al numero di record}
\end{figure}
\noindent
Tuttavia dal grafico non emerge chiaramente quale parametro influenzi maggiormente la durata dell'elaborazione. Segue un'analisi pi\`u dettagliata su alcune combinazioni di parametri.
\clearpage
\subsection{Raggio spaziale e numero record}
Nei grafici che seguono in Figura 5.2 viene mostrato l'andamento del tempo di computazione in funzione di $R$ e del numero dei record. In ciascun caso vengono considerati i test con valore di $T$ uguale, in modo che esso non influenzi l'andamento del tempo di computazione. 
 
\begin{figure}[h]
	\hspace{-1.3cm}
	\includegraphics[height=0.8 \linewidth]{rag_nrec.png}
	\caption{tempi di computazione in funzione al raggio spaziale e al numero record}
\end{figure}
\noindent
Come ci si pu\`o aspettare, man mano che $R$ e il numero di record crescono, il tempo di computazione aumenta, ma non in modo uniforme per entrambe le variabili.\\
Si nota infatti che il raggio spaziale $R$ ha un impatto maggiore nei tempi rispetto all'incremento legato al numero record che, pur non essendo lineare, \`e di entit\`a minore in confronto a quello legato ad $R$.
\clearpage

\subsection{Intervallo temporale e numero record}
Nei grafici che seguono in Figura 5.3 viene mostrato l'andamento del tempo di computazione in funzione di $T$ e del numero dei record. Per ogni grafico vengono considerati i test con valore di $R$ uguale, in modo che esso non influenzi l'andamento del tempo di computazione. 

\begin{figure}[h]
	\hspace{-1.5cm}
	\includegraphics[height=0.85 \linewidth]{tem_nrec.png}
	\caption{tempi di computazione in funzione all'intervallo temporale e al numero record}
\end{figure}

\noindent
Analogamente ai test considerati in precedenza, all'aumentare del valore delle variabili il tempo di computazione aumenta pi\`u che proporzionalmente. \\
In questo caso, per\`o, \`e il numero di record che influenza maggiormente il tempo di computazione. Ci\`o che si nota \`e che l'incremento legato a $T$ \`e meno marcato rispetto a quello legato al numero record.
\clearpage

\subsection{Raggio e intervallo temporale}
Nei grafici che seguono in Figura 5.4 viene mostrato l'andamento del tempo di computazione in funzione di $R$ e $T$. Per ogni grafico vengono considerati i test con uno numero di record uguale, in modo tale che esso non influenzi l'andamento del tempo di computazione. 

\begin{figure}[h]
	\hspace{-1cm}
	\includegraphics[height=0.9 \linewidth]{rag_temp.png}
	\caption{tempi di computazione in funzione all'intervallo temporale e al numero record}
\end{figure}
\noindent
Da questi grafici si evince che entrambe le variabili influenzano in modo significativo il tempo di computazione. Si nota comunque che, in particolare per numero di record pi\`u elevato, $R$ ha maggiore influenza rispetto a $T$. La differenza non \`e cos\`i marcata, anzi, fa eccezione il caso di numero record = 1043 in cui $T$ scala maggiormente, situazione dovuta probabilmente al fatto che si hanno risultati molto ravvicinati e di basso tempo di computazione ($0-20$ secondi). 

\paragraph{In conclusione} si pu\`o dire che tutte e tre le variabili studiate hanno un impatto significativo sul tempo di computazione, ma $R$ e il \textit{numero record} lo influenzano maggiormente rispetto a $T$.
\clearpage

\section{Indici}
La seconda parte dell'analisi riguarda i risultati ottenuti. Per poter valutare correttamente l'importanza degli stessi vengono utilizzati degli indici.\\
L'indice pi\`u signficativo \`e sicuramente il \textit{participation index}, ma accanto a quello ne sono stati considerati altri: il \textbf{supporto}, la \textbf{confidenza} e il \textbf{lift}.
\subsection{Supporto}
Supponiamo di dover trattare un \textit{market basket problem} in cui si considerano gli acquisti di caff\`e e t\`e. Per analizzare le possibili regole di associazione viene utilizzata una \textit{contingency table}. Una \textit{contingency table} \`e una tabella che evidenzia le frequenze assolute della vendita dei prodotti in base alle intersezioni di righe e colonne della tabella. Di seguito un esempio:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		& \textbf{caff\`e} & \textbf{no caff\`e} & \\
		\hline
		\textbf{t\`e} & 150 & 50 & \textbf{200} \\
		\hline
		\textbf{no t\`e} & 650 & 150 & \textbf{800} \\
		\hline
		& \textbf{800} & \textbf{200} & \textcolor{red}{\textbf{1000}} \\
		\hline
	\end{tabular}
	\caption{esempio di contingency table}
\end{table}
\noindent
Come si evince dalla Tabella 5.2 gli acquisti di t\`e sono stati 200, quelli di caff\`e sono stati 800 (totale 1000 transazioni) ma solo 150 clienti hanno acquistato entrambi i prodotti. Come si pu\`o notare che 650 clienti hanno acquistato caff\`e ma non t\`e.\\
Consideriamo la sequenza $A \rightarrow B$.\\
Il supporto a questa sequenza \`e dato dal rapporto delle transazioni che includono i due prodotti rispetto alle transazioni totali ovvero:

$s(A \rightarrow B) = ${\large $\frac{\sigma\{A, B\}}{|T|}$}\\
dove $|T|$ \`e il numero delle transazioni totali. \\
Sostanzialmente indica la percentuale di transazioni che contengono entrambre $A$ e $B$.\\
\\
Nel nostro esempio consideriamo la sequenza $t\grave{e} \rightarrow caff\grave{e}$:

$s(t\grave{e} \rightarrow caff\grave{e}) = ${\large $\frac{\sigma\{t\grave{e}, caff\grave{e}\}}{|T|}$} $ = ${\large $\frac{150}{1000}$} $ = 0.15 = 15\%$\\
quindi il 15\% degli acquisti considerati sono di entrambi, t\`e e caff\`e. 

\subsection{Confidenza}
L'altro indice considerato nell'analisi \`e quello della \textit{confidenza}.\\
La confidenza indica, date le transazioni che contengono $A$, qual \`e la percentuale di transazioni che contengono $B$.\\
Data una regola di associazione $A \rightarrow B$ la confidenza modella la probabilit\`a della presenza di $B$ nella transazione \textit{condizionata} dalla presenza di $A$, formalmente:

$c(A \rightarrow B) = P(B|A) = ${\large $\frac{P(A,B)}{P(A)}$} $=$ {\large $\frac{\sigma\{A,B\}}{|T|} \frac{|T|}{\sigma\{A\}}$}$ = ${\large $\frac{\sigma\{A,B\}}{\sigma\{A\}}$}\\
\\
Nel nostro esempio:

$c(t\grave{e} \rightarrow caff\grave{e}) = P(caff\grave{e}|t\grave{e}) = ${\large $\frac{150}{200}$}$ = 0,75 = 75\%$\\
$75\%$ \`e una percentuale alta per la quale l'acquisto del caff\`e \`e condizionato dall'acquisto del t\`e, non va dimenticato per\`o che il supporto \`e solo del $15\%$. Per comprendere meglio la dipendenza di un evento rispetto ad un altro viene utilizzato l'indice \textit{lift}.

\subsection{Lift}
Il limite della confidenza \`e che non considera il supporto del dataset nella parte destra della regola, quindi non fornisce una valutazione corretta nel caso in cui gli elementi della sequenza non siano stocasticamente indipendenti.\\
Nel nostro esempio si denota che molte delle persone che bevono t\`e bevono anche caff\`e ma non si considera quante persone in totale bevono caff\`e.\\
L'indice che tiene in considerazione questa situazione \`e il \textit{Lift}:

$Lift(A \rightarrow B) = $ {\large $\frac{c(A \rightarrow B)}{s(B)}$} $ = $ {\large $\frac{P(B|A)}{P(B)}$} $ = $ {\large $\frac{P(B,A)}{P(A) P(B)}$}

\begin{itemize}
	\item se $lift = 1$ gli eventi sono indipendenti
	\item se $lift > 1$ gli eventi sono correlati positivamente ($P(A \rightarrow B) > P(B)$)
	\item se $lift < 1$ gli eventi sono correlati negativamente
\end{itemize} 
\noindent
Nel nostro esempio:

$Lift(t\grave{e} \rightarrow caff\grave{e}) = $ {\large $\frac{c(t\grave{e} \rightarrow caff\grave{e})}{s(caff\grave{e})}$} $ = $ {\large $\frac{0.75}{0.8}$} $ = 0.9375 < 1$\\
il valore \`e $< 1$ pertanto vi \`e correlazione negativa per cui la regola in questione \underline{non} \`e da considerare interessante.\\
\\

\section{Analisi}
Prima di procedere all'anlisi vera e propria dei risultati \`e bene fare alcune premesse. Di seguito viene analizzata una particolare configurazione di parametri applicata ad un dataset scelto.\\ 
\`E stato scelto il dataset $3$, quello con $3129$ record, e i parametri $R = 2$, $T = 168$ in quanto presenta dei risultati variegati ai quali si possono fare diverse osservazioni, soprattutto sugli indici.\\
Ne vediamo di seguito un piccolo estratto:

\begin{table}[h]
	\hspace{-0.75cm}
	\begin{tabular}{m{8cm}|c|c|c|c}
		\centering \textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confid} & \textbf{Lift} \\
		\hline
		$[$'Larceny', 'Robbery'$]$ & 0.8727 & 0.046 & 0.8727 & 16,5598 \\
		$[$'Larceny', 'Commercial Burglary'$]$ & 0.8644 & 0.0163 & 0.8644 & 45.7354 \\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Commercial Burglary'$]$ & 0.7157 & 0.0147 & 0.7797 & 41.2540 \\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Aggravated Assault', 'Other Burglary'$]$ & 0.7157 & 0.0048 & 0.75 & 117.1875 \\
		$[$'Aggravated Assault', 'Larceny', 'Residential Burglary'$]$ & 0.6428 & 0.0521 & 0.7026 & 9.4818 \\
		$[$'Aggravated Assault', 'Larceny From Motor Vehicle', 'Auto Theft'$]$ &  0.6259 & 0.0479 & 0.6356 & 8.4297 \\
	\end{tabular}
	\caption{estratto dei risultati}
\end{table}
\noindent
Come si pu\`o notare, le sequenze di lunghezza 2 hanno tendenzialmente un \textit{PI} maggiore rispetto alle sequenze di lunghezza maggiore. Questo fatto \`e triviale in quanto le istanze coinvolte all'aumentare del numero di elementi della sequenza diminuisce e pertanto il \textit{PI} segue questa tendenza. Lo si comprende anche pensando alla struttura ad albero, in cui, man mano che si inseriscono nodi in profondit\`a, la significativit\`a della sequenza diminuisce, quindi il \textit{PI}.\\
\\
Un'altra osservazione che si pu\`o fare \`e che, sempre per le sequenze di lunghezza 2, il \textit{PI} e la \textit{confidenza} hanno valori sostanzialmente uguali. Anche in questo caso la spiegazione \`e piuttosto semplice in quanto la confidenza calcola quanto l'ultimo elemento della sequenza influenza quelli precedenti ed \`e lo stesso calcolo del \textit{participation rateo} a cui il \textit{PI} si appoggia. Naturalmente, considerando sequenze di lunghezza maggiore, i due valori differscono.

\paragraph{Supporto} Il supporto calcolato sulle varie sequenze \`e tendenzialmente basso. La media dei supporti delle sequenze trovate \`e di circa il 5\% (vedi Figura 5.5). Il valore medio \`e basso in quanto il dataset \`e diviso in 9 classi di eventi e ciascuna classe ha una diversa frequenza, ad esempio \textit{larceny} \`e la classe con la frequenza maggiore. Pertanto possiamo considerare come sequenze significative quelle che hanno un supporto maggiore o paragonabile al 5\%.
 
\paragraph{Lift} L'indice \textit{lift}, come si pu\`o osservare dall'estratto della Tabella 5.3 \`e sostanzialmente sempre $> 1$. Essendo che una regola con un \textit{lift} $> 1$ significa che \`e una regola positivamente correlata, le sequenze estratte dall'algoritmo STBFM sono tutte significative rispetto al loro contesto. In alcuni test, quando vengono estratte sequenze di basso $PI$, il \textit{lift} pu\`o risultare $<1$ ma questo non succede quando si imposta un threshold di partenza sufficientemente grande. Il \textit{lift} di conseguenza conferma l'utilit\`a di utilizzare un threshold dinamico e un numero fissato di risultati $Top$ per non perdersi in sequenze poco rilevanti.

\paragraph{Confidenza} La confidenza calcolata sui risultati \`e relativa all'ultimo elemento della sequenza. Ad esempio consideriamo la sequenza: $[$'Larceny From Motor Vehicle', 'Larceny', 'Commercial Burglary'$]$, essa ha un $PI = 0.7157$ ma una $confidenza = 0.75$. Significa che la sequenza in s\`e ha un indice di partecipazione attorno al $71\%$ ma la sequenza di eventi $[$'Larceny From Motor Vehicle', 'Larceny'$]$ ha come conseguenza un Commercial Burglary al $75\%$.\\
\\
Gli indici di \textbf{PI} e \textbf{confidenza} combinati con il \textbf{supporto}, per comprendere l'incidenza del fenomeno, permettono di dare un significato pi\`u chiaro e possibilmente utile alle associazioni trovate.\\
\\
Per analizzare le sequenze pi\`u significative di lunghezza $> 2$ si considerano le frequenze percentuali delle varie classi in questo particolare dataset:

\begin{figure}[h]
	\hspace{-1.2cm}
	\includegraphics[height=0.68 \linewidth]{freqRel.png}
	\caption{frequenze percentuali dei tipi dataset 3}
\end{figure}

\vspace{10cm}
\noindent
Come si pu\`o notare, le proporzioni tra i tipi rispetto alle frequenze del dataset principale (vedi Figura 4.1) sono sostanzialmente mantenute.\\
\\
Di seguito vengono riportati alcuni esempi di sequenze e la discussione dei rispettivi indici.

\paragraph{Esempio 1} Ora prendiamo un esempio di sequenza di lunghezza 3 con alto PI e confidenza.

\begin{table}[h]
	\hspace{-0.5cm}
	\begin{tabular}{m{8cm}|c|c|c}
		\centering \textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confidence} \\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Other Burglary'$]$ & 0.7157 & 0,0058 & 0.9 \\
	\end{tabular}
\end{table}

\noindent
Con un $PI$ al $71.57\%$ questa sequenza \`e da considerarsi signficativa. La confidenza allo 0.9 inolte ci comunica che se vi \`e stato un Larceny From Motor Vehicle (furto in auto) e successivamente un Larceny (furto) allora con una correlazione del 90\% avverr\`a un Other Burglary (furto con scasso) nello stesso raggio temporale e spaziale. \`E una conclusione molto potente ma non bisogna dimenticare che il supporto a questa affermazione \`e molto basso (circa lo $0.58\%$), ovvero il numero di istanze che influenza \`e esiguo. Va considerato che il poco supporto \`e dovuto indubbiamente anche alla bassa frequenza che ha Other Burglary sul totale delle istanze ($0.64\%$).

\paragraph{Esempio 2} Prendiamo in considerazione un altro esempio.

\begin{table}[h]
	\hspace{-0.5cm}
	\begin{tabular}{m{8cm}|c|c|c}
		\centering \textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confidence} \\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Aggravated Assault'$]$ & 0.7157 & 0,0991 & 0.7543 \\
	\end{tabular}
\end{table}
\noindent
La sequenza presa in esame presenta un \textit{PI} del $71.57\%$, quindi molto buono, un livello di confidenza dell'ultimo elemento del $75.43\%$, altrettanto alto, e un supporto del $9.91\%$. Il livello di supporto a questa sequenza \`e decisamente maggiore rispetto all'esempio precedente, infatti, a parit\`a di di \textit{PI}, la sequenza presente \`e molto pi\`u interessante ed utilizzabile.\\
Va per\`o evidenziato un aspetto relativo a questi due esempi, ovvero che i primi due elementi della sequenza sono gli stessi: Larceny From Motor Vehicle e Larceny. Ci\`o ignifica che essi sono altamente correlati ed influenzano molti tipi di eventi successivi.

\paragraph{Esempio 3} Consideriamo ora un caso di sequenza di lunghezza 4.

\begin{table}[h]
	\hspace{-0.5cm}
	\begin{tabular}{m{8cm}|c|c|c}
		\centering \textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confidence} \\
		$[$'Larceny', 'Aggravated Assault', 'Larceny From Motor Vehicle', 'Auto Theft'$]$ & 0.6184 & 0,0479 & 0.6356 \\
	\end{tabular}
\end{table}
\noindent
Si nota subito un valore \textit{PI} minore rispetto agli altri, $61.84\%$; \`e fisiologico un \textit{participation index} minore rispetto alle sequenze con meno elementi. La confidenza \`e del $63.56\%$, un valore buono ma nulla di troppo significativo. Il supporto \`e del $4.79\%$, un valore non elevato ma neanche irrisorio.\\
L'associazione analizzata  attraverso i suoi indici non ci comunica un grado di affidabilit\`a consistente e ci\`o \`e un fatto comune per le sequenze di lunghezza 4 nelle quali gli indicatori tendono ad assumere valori medi o comunque non decisamente elevati.\\
\clearpage
\noindent
Di seguito le sequenze di lunghezza $> 2$ considerate pi\`u significative rispetto alle altre:

\begin{table}[h]
	\hspace{-0.5cm}
	\begin{tabular}{m{8cm}|c|c|c|c}
		\centering \textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confidence} & \textbf{Lift} \\
		\hline
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Aggravated Assault'$]$ & 0.7157 & 0,0991 & 0.7543 & 5,7405
		\\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Auto Theft'$]$ & 0.7157 & 0,0575 & 0.7627 & 10,1154
		\\
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Residential Burglary'$]$ & 0.6907 & 0,0508 & 0.6853 & 9,2483
		\\
		$[$'Larceny', 'Larceny From Motor Vehicle', 'Auto Theft'$]$ & 0.6853 & 0,0521 & 0.6907 & 9,1605
		\\ 
		$[$'Aggravated Assault', 'Larceny', 'Larceny From Motor Vehicle'$]$ & 0.6428 & 0,1262 & 0.7425 & 4,3676
		\\
		$[$'Aggravated Assault', 'Larceny', 'Residential Burglary'$]$ & 0.6428 & 0,0521 & 0.7026 & 9,4818
		\\
		$[$'Aggravated Assault', 'Larceny', 'Larceny From Motor Vehicle', 'Auto Theft'$]$ & 0.6356 & 0,0479 & 0.6356 & 8,4297
		 \\		
	\end{tabular}
\end{table}
