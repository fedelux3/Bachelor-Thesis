\chapter{Analisi dei risultati}
\label{Analisi}
\pagestyle{empty}

La performance del software \`e stata valutata tramite diversi test in cui vengono utilizzati database con diverso numero di record e diverse combinazioni di parametri.
\\\\
Il database di partenza utilizzato \`e quello relativo al Boston Crime Department del 2018 descritto nel capitolo precedente con $15\,648$ record. Non \`e stato utilizzato per\`o direttamente in quanto il numero di record \`e molto elevato. Con un alto numero di record il tempo di elaborazione aumenta eccessivamente, pertanto si \`e preferito testare il software in suoi sottoinsiemi.\\
Per la generazione dei dataset sottoinsiemi viene copiato un record ogni $N$, in questo modo si mantengono le proporzioni delle frequenze tra i diversi tipi di eventi.\\
Sono stati generati 4 dataset sottoinsieme ed hanno i seguenti numeri di record:
\begin{enumerate}
	\item 1043 - 1 ogni 15 record
	\item 2235 - 1 ogni 7 record
	\item 3129 - 1 ogni 5 record
	\item 5216 - 1 ogni 3 record
\end{enumerate}
\noindent
I parametri utilizzati sono stati: $\theta$, numero di sequenze top ($Num$), $R$, $T$.

\paragraph{Il threshold $\theta$} \`e stato fissato a $0.25$, in quanto \`e il valore consigliato dal paper. Essendo un valore basso, l'algoritmo esclude a priori le sequenze poco significative e man mano incrementa il threshold per adattarlo al numero delle sequenze considerate nell'insieme $Top$, nel caso in cui esso superi il massimo numero di elementi consentito ($Num$).

\paragraph{Il numero di sequenze top $Num$} da considerare nel insieme $Top$ di output \`e stato fissato a 50, ovvero come output si considerano solo le prime cinquanta sequenze di tipi per \textit{participation index}. Il valore \`e frutto del compromesso tra numero di sequenze significative da visualizzare e tempi di computazione. Se si scegliesse un valore minore non si avrebbero sequenze di tipi significativi probabilmente utili. Se si segliesse un valore maggiore i tempi di computazione lieviterebbero esponenzialmente; inoltre, le sequenze ricavate oltre la cinquantesima posizione avranno, con alta probabilit\`a, un $PI$ basso, quindi poco rilevanti.
\\\\
I parametri di \textbf{raggio spaziale $R$} e \textbf{intervallo temporale $T$} sono variabili che vengono fissate in base al test da effettuare.\\
I valori scelti di questi due parametri sono variano entro i seguenti range:
\begin{itemize}
	\item $R$ varia da 1 a 3 km
	\item $T$ varia da 72 a 168 ore (da 3 giorni a 7 giorni)
\end{itemize} 
\clearpage

\section{Tempi di computazione}
La prima parte dell'analisi fatta riguarda i tempi di computazione e in particolare lo studio di come scala all'aumentare dei record il tempo di elaborazione. Sono state scelte 12 combinazioni dei parametri $R$ e $T$, applicate a tutti i quattro dataset. In concreto vi sono $12 \times 4 = 48$ test, 12 combinazioni per 4 dataset.\\
In Tabella 5.1 vengono mostrati i test effettuati con i tempi di computazione, suddivisi in base a: raggio spaziale, intervallo temporale e numero di record.

\begin{table}[h]
	\centering
	\begin{tabular}{c|c|c|c|c|c|c}
		\hline
		\multirow{2}{1cm}{\textbf{comb}} & \multirow{2}{2.2cm}{\textbf{raggio spaziale}} & \multirow{2}{2.2cm}{\textbf{intervallo temporale}} & \multicolumn{4}{c}{\textbf{tempo per numero di record}} \\
		& & & \textbf{1043} & \textbf{2235} & \textbf{3129} & \textbf{5216} \\
		\hline
		1 & 2 & 168 & 10 & 87 & 198 & 693 \\
		2 & 1.5 & 168 & 7 & 50 & 158 & 538 \\
		3 & 1.5 & 120 & 7 & 42 & 116 & 475 \\
		4 & 3 & 120	& 13 & 105 & 247 & 815 \\
		5 & 1 & 120 & 7 & 30 & 71 & 234 \\
		6 & 1 & 72 & 7 & 30 & 60 & 182 \\
		7 & 2 & 120 & 8 & 68 & 181 & 624 \\
		8 & 3 & 72 & 9 & 81 & 204 & 668 \\
		9 & 1.5 & 72 & 7 & 33 & 74 & 307 \\
		10 & 3 & 168 & 20 & 117 & 267 & 818 \\
		11 & 2 & 72 & 7 & 43 & 115 & 492 \\
		12 & 1 & 168 & 7 & 32 & 85 & 362 \\
		\hline
	\end{tabular}
	\caption{tempi in secondi dei test effettuati}
\end{table}
\noindent
Per comprendere come il software scali per numero di record vengono fissati i parametri di raggio spaziale $R$ e intervallo temporale $T$, in questo modo \`e possibile valutare l'andamento del tempo di computazione legato alla sola variazione di numero di record. Seguendo la procedura per tutte le combinazioni di raggio e tempo utilizzate ne risulta il grafico in Figura 5.1.\\
Una linea del grafico rappresenta una serie di test effettuati sui tutti i quattro dataset fissando una coppia di parametri $R$ e $T$. Le serie di test vengono effettuate per tutte le 12 combinazioni e i risultati rappresentati in figura.\\
\\
Come era prevedibile, i test che impiegano pi\`u tempo ad essere elaborati sono quelli con \textit{neighborhood} pi\`u ampio, sia per quanto riguarda il raggio spaziale sia quello temporale.\\
Un aspetto rilevante \`e l'andamento \textbf{non lineare} del tempo all'aumentare del numero di record. Al contrario, con un numero sufficientemente alto di record, si pu\`o pensare che il software tenda ad un tempo esponenziale. Lo si evince soprattutto quando il numero di record sale da $3129$ a $5216$.\\
Da notare inoltre che per un \textit{vicinato} pi\`u ristretto, l'incremento dei tempi legato al numero di record \`e meno marcato, ad esempio per $R = 1 $, $ T = 72$.

\begin{figure}[h]
	\hspace{-3cm}
	\includegraphics[height=0.75 \linewidth]{tempi12.png}
	\caption{tempi di computazione in relazione al numero di record}
\end{figure}
\noindent
Dal grafico per\`o \`e non emerge chiaramente quale parametro influenza maggiormente la durata dell'elaborazione. Segue un'analisi pi\`u dettagliata su alcune combinazioni di parametri.
\clearpage
\subsection{Raggio spaziale e numero record}
Nei grafici che seguono in Figura 5.2 viene mostrato l'andamento del tempo di computazione in funzione di $R$ e del numero dei record. In ciascun caso vengono considerati i test con valore di $T$ uguale, in modo che esso non influenzi l'andamento del tempo di computazione. 
 
\begin{figure}[h]
	\hspace{-1.3cm}
	\includegraphics[height=0.8 \linewidth]{rag_nrec.png}
	\caption{tempi di computazione in funzione al raggio spaziale e al numero record}
\end{figure}
\noindent
Come ci si pu\`o aspettare man mano che $R$ e il numero di record crescono, il tempo di computazione aumenta, ma non in modo uniforme per entrambe le variabili.\\
Si nota infatti che il raggio spaziale $R$ ha un impatto maggiore nei tempi rispetto all'incremento legato al numero record che, pur non essendo lineare, \`e di entit\`a minore in confronto a quello legato ad $R$.
\clearpage

\subsection{Intervallo temporale e numero record}
Nei grafici che seguono in Figura 5.3 viene mostrato l'andamento del tempo di computazione in funzione di $T$ e del numero dei record. Per ogni grafico vengono considerati i test con valore di $R$ uguale, in modo che esso non influenzi l'andamento del tempo di computazione. 

\begin{figure}[h]
	\hspace{-1.5cm}
	\includegraphics[height=0.85 \linewidth]{tem_nrec.png}
	\caption{tempi di computazione in funzione all'intervallo temporale e al numero record}
\end{figure}

\noindent
Analogamente ai test considerati in precedenza, all'aumentare del valore delle variabili il tempo di computazione aumenta pi\`u che proporzionalmente. \\
In questo caso, per\`o, \`e il numero di record che influenza maggiormente il tempo di computazione. Osservando si nota che l'incremento legato a $T$ \`e meno marcato rispetto a quello legato al numero record.
\clearpage

\subsection{Raggio e intervallo temporale}
Nei grafici che seguono in Figura 5.4 viene mostrato l'andamento del tempo di computazione in funzione di $R$ e $T$. Per ogni grafico vengono considerati i test con uno numero di record uguale, in modo tale che esso non influenzi l'andamento del tempo di computazione. 

\begin{figure}[h]
	\hspace{-1cm}
	\includegraphics[height=0.9 \linewidth]{rag_temp.png}
	\caption{tempi di computazione in funzione all'intervallo temporale e al numero record}
\end{figure}
\noindent
Da questi grafici si evince che entrambe le variabili influenzano in modo significativo il tempo di computazione. Si nota comunque che, in particolare per numero di record pi\`u elevato, $R$ ha maggiore influenza rispetto a $T$. La differenza non \`e cos\`i marcata, anzi, fa eccezione il caso di numero record = 1043 in cui $T$ scala maggiormente, situazione dovuta probabilmente al fatto che si hanno risultati molto ravvicinati e di basso tempo di computazione ($0-20$ secondi). 

\paragraph{In conclusione} si pu\`o dire che tutte e tre le variabili studiate hanno un impatto significativo sul tempo di computazione, ma $R$ e il \textit{numero record} lo influenzano maggiormente rispetto a $T$.
\clearpage

\section{Indici}
La seconda parte dell'analisi riguarda i risultati ottenuti. Per poter valutare correttamente l'importanza degli stessi vengono utilizzati degli indici.\\
L'indice pi\`u signficativo \`e sicuramente il \textit{participation index}, ma accanto a quello ne sono stati considerati altri: il \textbf{supporto}, la \textbf{confidenza} e il \textbf{lift}.
\subsection{Supporto}
Supponiamo di dover trattare un \textit{market basket problem} in cui si considerano gli acquisti di caff\`e e t\`e. Per analizzare le possibili regole di associazione viene utilizzata una \textit{contingency table}. Una \textit{contingency table} \`e una tabella che evidenzia le frequenze assolute della vendita dei prodotti in base alle intersezioni di righe e colonne della tabella. Di seguito un esempio:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		& \textbf{caff\`e} & \textbf{no caff\`e} & \\
		\hline
		\textbf{t\`e} & 150 & 50 & \textbf{200} \\
		\hline
		\textbf{no t\`e} & 650 & 150 & \textbf{800} \\
		\hline
		& \textbf{800} & \textbf{200} & \textcolor{red}{\textbf{1000}} \\
		\hline
	\end{tabular}
	\caption{esempio di contingency table}
\end{table}
\noindent
Come si evince dalla Tabella 5.2 gli acquisti di t\`e sono stati 200, quelli di caff\`e sono stati 800 (totale 1000 transazioni) ma solo 150 clienti hanno acquistato entrambi i prodotti. Come si pu\`o notare che 650 clienti hanno acquistato caff\`e ma non t\`e.\\
Consideriamo la sequenza $A \rightarrow B$.\\
Il supporto a questa sequenza \`e dato dal rapporto delle transazioni che includono i due prodotti rispetto alle transazioni normali ovvero:

$s(A \rightarrow B) = ${\large $\frac{\sigma\{A, B\}}{|T|}$}\\
dove $|T|$ \`e il numero delle transazioni totali. \\
Sostanzialmente indica la percentuale di transazioni che contengono entrambre $A$ e $B$.\\
\\
Nel nostro esempio consideriamo la sequenza $t\grave{e} \rightarrow caff\grave{e}$:

$s(t\grave{e} \rightarrow caff\grave{e}) = ${\large $\frac{\sigma\{t\grave{e}, caff\grave{e}\}}{|T|}$} $ = ${\large $\frac{150}{1000}$} $ = 0.15 = 15\%$\\
quindi il 15\% degli acquisti considerati sono di entrambi, t\`e e caff\`e. 

\subsection{Confidenza}
L'altro indice considerato nell'analisi \`e quello della \textit{confidenza}.\\
La confidenza indica, date le transazioni che contengono $A$, qual \`e la percentuale di transazioni che contengono $B$.\\
Data una regola di associazione $A \rightarrow B$ la confidenza modella la probabilit\`a della presenza di $B$ nella transazione \textit{condizionata} dalla presenza di $A$, formalmente:

$c(A \rightarrow B) = P(B|A) = ${\large $\frac{P(A,B)}{P(A)}$} $=$ {\large $\frac{\sigma(A,B)}{|T|} \frac{|T|}{\sigma(A)}$}$ = ${\large $\frac{\sigma(A,B)}{\sigma(A)}$}\\
\\
Nel nostro esempio:

$c(t\grave{e} \rightarrow caff\grave{e}) = P(caff\grave{e}|t\grave{e}) = ${\large $\frac{150}{200}$}$ = 0,75 = 75\%$\\
$75\%$ \`e una percentuale alta per la quale l'acquisto del caff\`e \`e condizionato dall'acquisto del t\`e, non va dimenticato per\`o che il supporto \`e solo del $15\%$. Per comprendere meglio la dipendenza di un evento rispetto ad un altro viene utilizzato l'indice \textit{lift}.

\subsection{Lift}
Il limite della confidenza \`e che non considera il supporto del dataset nella parte destra della regola, quindi non fornisce una valutazione corretta nel caso in cui gli elementi della sequenza non siano stocasticamente indipendenti.\\
Nel nostro esempio si valuta che molte delle persone che bevono t\`e bevono anche caff\`e ma non si considera quante persone in totale bevono caff\`e.\\
L'indice che tiene in considerazione questa situazione \`e il \textit{Lift}:

$Lift(A \rightarrow B) = $ {\large $\frac{c(A \rightarrow B)}{s(B)}$} $ = $ {\large $\frac{P(B|A)}{P(B)}$} $ = $ {\large $\frac{P(B,A)}{P(A) P(B)}$}

\begin{itemize}
	\item se $lift = 1$ gli eventi sono indipendenti
	\item se $lift > 1$ gli eventi sono correlati positivamente ($P(A \rightarrow B) > P(B)$)
	\item se $lift < 1$ gli eventi sono correlati negativamente
\end{itemize} 
\noindent
Nel nostro esempio:

$Lift(t\grave{e} \rightarrow caff\grave{e}) = $ {\large $\frac{c(t\grave{e} \rightarrow caff\grave{e})}{s(caff\grave{e})}$} $ = $ {\large $\frac{0.75}{0.8}$} $ = 0.9375 < 1$\\
il valore \`e $< 1$ pertanto vi \`e correlazione negativa per cui la regola in questione \underline{non} \`e da considerare interessante.\\
\\

\section{Analisi}
Prima di procedere all'anlisi vera e propria dei risultati \`e bene fare alcune premesse. Di seguito viene analizzata una particolare configurazione di parametri applicata ad un dataset scelto.\\ 
\`E stato scelto il dataset $3$, quello con $3\,129$ record, e i parametri $R = 2$, $T = 168$ in quanto presenta dei risultati variegati ai quali si possono fare diverse osservazioni soprattutto sugli indici.\\
Ne vediamo di seguito un piccolo estratto:

\begin{table}[h]
	\hspace{-0.75cm}
	\begin{tabular}{|p{8cm}|c|c|c|c|}
		\hline
		\textbf{Sequenza} & \textbf{PI} & \textbf{Support} & \textbf{Confid} & \textbf{Lift} \\
		\hline
		$[$'Larceny', 'Robbery'$]$ & 0.8727 & 0.046 & 0.8727 & 16,5598 \\
		\hline
		$[$'Larceny', 'Commercial Burglary'$]$ & 0.8644 & 0.0163 & 0.8644 & 45.7354 \\
		\hline
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Commercial Burglary'$]$ & 0.7157 & 0.0147 & 0.7797 & 41.2540 \\
		\hline
		$[$'Larceny From Motor Vehicle', 'Larceny', 'Aggravated Assault', 'Other Burglary'$]$ & 0.7157 & 0.0048 & 0.75 & 117.1875 \\
		\hline
		$[$'Aggravated Assault', 'Larceny', 'Residential Burglary'$]$ & 0.6428 & 0.0521 & 0.7026 & 9.4818 \\
		\hline
		$[$'Aggravated Assault', 'Larceny From Motor Vehicle', 'Auto Theft'$]$ &  0.6259 & 0.0479 & 0.6356 & 8.4297 \\
		
		\hline
	\end{tabular}
	\caption{estratto dei risultati}
\end{table}
\noindent
Come si pu\`o notare le sequenza di lunghezza 2 hanno tendenzialmente un \textit{PI} maggiore rispetto alle sequenze di lunghezza maggiore. Questa fatto \`e triviale in quanto le istanze coinvolte all'aumentare del numero di elementi della sequenza diminuisce e pertanto il \textit{PI} segue questa tendenza. Lo si comprende anche pensando alla struttura ad albero, man mano che si inseriscono nodi in profonditÃ , la significativit\`a della sequenza diminuisce, quindi il \textit{PI}.\\
\\
Un'altra osservazione che si pu\`o fare \`e che, sempre per le sequenze di lunghezza 2, il \textit{PI} e la \textit{confidenza} hanno valori sostanzialmente uguali. Anche in questo caso la spiegazione \`e piuttosto semplice in quanto la confidenza calcola quanto l'ultimo elemento della sequenza influenza quelli precedenti ed \`e lo stesso calcolo del \textit{participation rateo} a cui il \textit{PI} si appoggia. Naturalmente considerando sequenze di lunghezza maggiore, i due valori differscono.
\paragraph{Lift}